{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "import dgl\n",
    "import networkx as nx\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tensorboardX import SummaryWriter\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import ipdb\n",
    "import h5py\n",
    "import pickle\n",
    "import argparse\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "import utils.io as io\n",
    "from model.cnn_model import HOCNN\n",
    "from datasets import metadata\n",
    "from utils.vis_tool import vis_img\n",
    "from datasets.hico_constants import HicoConstants\n",
    "from datasets.hico_dataset import HicoDataset, collate_fn\n",
    "\n",
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(21)\n",
    "np.random.seed(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data paths\n",
    "TRAIN_IMG_PATH = \"datasets/hico/images/train2015/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on cuda\n"
     ]
    }
   ],
   "source": [
    "# Setup training device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('training on {}'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment v1_2020-11-02_22-41\n"
     ]
    }
   ],
   "source": [
    "# Define arguments\n",
    "batch_size = 32\n",
    "epochs = 80\n",
    "initial_lr = 0.00001\n",
    "\n",
    "feat_type = 'fc7'\n",
    "data_aug = False\n",
    "exp_ver = 'v1_' + datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M\")\n",
    "save_dir = './checkpoints/hico'\n",
    "log_dir = './log/hico'\n",
    "save_every = 5\n",
    "print_batch_every = 1000\n",
    "print_epoch_every = 1\n",
    "\n",
    "# set the cache size [0 means infinite]\n",
    "max_img_cache_size = 0#40000\n",
    "\n",
    "print('Running experiment ' + exp_ver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using fc7 feature...\n",
      "Using fc7 feature...\n",
      "set up dataset variable successfully\n",
      "set up dataloader successfully\n"
     ]
    }
   ],
   "source": [
    "# Define dataloaders\n",
    "data_const = HicoConstants(feat_type=feat_type)\n",
    "\n",
    "train_dataset = HicoDataset(data_const=data_const, subset='train', data_aug=data_aug)\n",
    "val_dataset = HicoDataset(data_const=data_const, subset='val', data_aug=False, test=True)\n",
    "dataset = {'train': train_dataset, 'val': val_dataset}\n",
    "print('set up dataset variable successfully')\n",
    "\n",
    "train_dataloader = DataLoader(dataset=dataset['train'], batch_size=batch_size, shuffle=True, collate_fn=collate_fn, drop_last=True)\n",
    "val_dataloader = DataLoader(dataset=dataset['val'], batch_size=batch_size, shuffle=True, collate_fn=collate_fn, drop_last=True)\n",
    "dataloader = {'train': train_dataloader, 'val': val_dataloader}\n",
    "print('set up dataloader successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "model = HOCNN().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of parameters in this model is 49.470376 million\n"
     ]
    }
   ],
   "source": [
    "# Display parameter information\n",
    "parameter_num = 0\n",
    "for param in model.parameters():\n",
    "    parameter_num += param.numel()\n",
    "print(f'The number of parameters in this model is {parameter_num / 1e6} million')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=initial_lr, weight_decay=0)\n",
    "#optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=0.9, weight_decay=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup visualization\n",
    "writer = SummaryWriter(log_dir=log_dir + '/' + exp_ver + '/' + 'epoch_train')\n",
    "io.mkdir_if_not_exists(os.path.join(save_dir, exp_ver, 'epoch_train'), recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has started!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jimmyl02/.conda/envs/Interact/lib/python3.6/site-packages/h5py/_hl/dataset.py:313: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  \"Use dataset[()] instead.\", H5pyDeprecationWarning)\n",
      "/home/jimmyl02/launchpad/interact/model/cnn_model.py:173: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(summed_results)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train] Epoch: 1/80 Batch: 100/952 Loss: 4.2054338455200195 Accuracy: 37.5\n",
      "[train] Epoch: 1/80 Batch: 200/952 Loss: 2.5796890258789062 Accuracy: 62.5\n",
      "[train] Epoch: 1/80 Batch: 300/952 Loss: 1.0726741552352905 Accuracy: 81.25\n",
      "[train] Epoch: 1/80 Batch: 400/952 Loss: 1.4348655939102173 Accuracy: 87.5\n",
      "[train] Epoch: 1/80 Batch: 500/952 Loss: 1.1617963314056396 Accuracy: 71.875\n",
      "[train] Epoch: 1/80 Batch: 600/952 Loss: 0.4214852750301361 Accuracy: 93.75\n",
      "[train] Epoch: 1/80 Batch: 700/952 Loss: 0.8860668540000916 Accuracy: 87.5\n",
      "[train] Epoch: 1/80 Batch: 800/952 Loss: 0.5305304527282715 Accuracy: 90.625\n",
      "[train] Epoch: 1/80 Batch: 900/952 Loss: 0.6691300868988037 Accuracy: 87.5\n",
      "[train] Epoch: 1/80 Loss: 1.971866421571304 Accuracy: 76.23216920806689 Execution time: 928.8520140647888\n",
      "[val] Epoch: 1/80 Batch: 100/238 Loss: 0.5386521220207214 Accuracy: 93.75\n",
      "[val] Epoch: 1/80 Batch: 200/238 Loss: 0.15670159459114075 Accuracy: 96.875\n",
      "[val] Epoch: 1/80 Loss: 0.3428497282004053 Accuracy: 94.43788534697626 Execution time: 231.8946657180786\n",
      "[train] Epoch: 2/80 Batch: 100/952 Loss: 0.048692647367715836 Accuracy: 100.0\n",
      "[train] Epoch: 2/80 Batch: 200/952 Loss: 0.6393517255783081 Accuracy: 90.625\n",
      "[train] Epoch: 2/80 Batch: 300/952 Loss: 0.4546913504600525 Accuracy: 96.875\n",
      "[train] Epoch: 2/80 Batch: 400/952 Loss: 0.29837313294410706 Accuracy: 93.75\n",
      "[train] Epoch: 2/80 Batch: 500/952 Loss: 0.055578190833330154 Accuracy: 100.0\n",
      "[train] Epoch: 2/80 Batch: 600/952 Loss: 0.06595358997583389 Accuracy: 100.0\n",
      "[train] Epoch: 2/80 Batch: 700/952 Loss: 0.01587820053100586 Accuracy: 100.0\n",
      "[train] Epoch: 2/80 Batch: 800/952 Loss: 0.010752291418612003 Accuracy: 100.0\n",
      "[train] Epoch: 2/80 Batch: 900/952 Loss: 0.0074407197535037994 Accuracy: 100.0\n",
      "[train] Epoch: 2/80 Loss: 0.2095818875749339 Accuracy: 96.19281849483522 Execution time: 550.0084450244904\n",
      "[val] Epoch: 2/80 Batch: 100/238 Loss: 0.08582453429698944 Accuracy: 96.875\n",
      "[val] Epoch: 2/80 Batch: 200/238 Loss: 0.08556544780731201 Accuracy: 96.875\n",
      "[val] Epoch: 2/80 Loss: 0.16452511316222748 Accuracy: 96.51056014692378 Execution time: 133.7030963897705\n",
      "[train] Epoch: 3/80 Batch: 100/952 Loss: 0.009947750717401505 Accuracy: 100.0\n",
      "[train] Epoch: 3/80 Batch: 200/952 Loss: 0.009352205321192741 Accuracy: 100.0\n",
      "[train] Epoch: 3/80 Batch: 300/952 Loss: 0.003753986209630966 Accuracy: 100.0\n",
      "[train] Epoch: 3/80 Batch: 400/952 Loss: 0.10354696214199066 Accuracy: 93.75\n",
      "[train] Epoch: 3/80 Batch: 500/952 Loss: 0.10265407711267471 Accuracy: 96.875\n",
      "[train] Epoch: 3/80 Batch: 600/952 Loss: 0.015148928388953209 Accuracy: 100.0\n",
      "[train] Epoch: 3/80 Batch: 700/952 Loss: 0.11003537476062775 Accuracy: 96.875\n",
      "[train] Epoch: 3/80 Batch: 800/952 Loss: 0.19402343034744263 Accuracy: 93.75\n",
      "[train] Epoch: 3/80 Batch: 900/952 Loss: 0.10283928364515305 Accuracy: 96.875\n",
      "[train] Epoch: 3/80 Loss: 0.11405929360678595 Accuracy: 97.3700606656829 Execution time: 553.5038986206055\n",
      "[val] Epoch: 3/80 Batch: 100/238 Loss: 0.09036707878112793 Accuracy: 96.875\n",
      "[val] Epoch: 3/80 Batch: 200/238 Loss: 0.08292422443628311 Accuracy: 96.875\n",
      "[val] Epoch: 3/80 Loss: 0.12789775257866384 Accuracy: 97.36324281778828 Execution time: 133.39015817642212\n",
      "[train] Epoch: 4/80 Batch: 100/952 Loss: 0.0029222627636045218 Accuracy: 100.0\n",
      "[train] Epoch: 4/80 Batch: 200/952 Loss: 0.008087058551609516 Accuracy: 100.0\n",
      "[train] Epoch: 4/80 Batch: 300/952 Loss: 0.003547246800735593 Accuracy: 100.0\n",
      "[train] Epoch: 4/80 Batch: 400/952 Loss: 0.0813240259885788 Accuracy: 96.875\n",
      "[train] Epoch: 4/80 Batch: 500/952 Loss: 0.0012318836525082588 Accuracy: 100.0\n",
      "[train] Epoch: 4/80 Batch: 600/952 Loss: 0.07274805754423141 Accuracy: 96.875\n",
      "[train] Epoch: 4/80 Batch: 700/952 Loss: 0.004870004020631313 Accuracy: 100.0\n",
      "[train] Epoch: 4/80 Batch: 800/952 Loss: 0.016640059649944305 Accuracy: 100.0\n",
      "[train] Epoch: 4/80 Batch: 900/952 Loss: 0.07010971754789352 Accuracy: 96.875\n",
      "[train] Epoch: 4/80 Loss: 0.0825650233601909 Accuracy: 97.64879488440728 Execution time: 534.5341513156891\n",
      "[val] Epoch: 4/80 Batch: 100/238 Loss: 0.054862916469573975 Accuracy: 96.875\n",
      "[val] Epoch: 4/80 Batch: 200/238 Loss: 0.07856597751379013 Accuracy: 96.875\n",
      "[val] Epoch: 4/80 Loss: 0.11913235721347074 Accuracy: 97.10087891906073 Execution time: 130.6268560886383\n",
      "[train] Epoch: 5/80 Batch: 100/952 Loss: 0.05970093235373497 Accuracy: 96.875\n",
      "[train] Epoch: 5/80 Batch: 200/952 Loss: 0.001915688393637538 Accuracy: 100.0\n",
      "[train] Epoch: 5/80 Batch: 300/952 Loss: 0.0011835077311843634 Accuracy: 100.0\n",
      "[train] Epoch: 5/80 Batch: 400/952 Loss: 0.07611402124166489 Accuracy: 96.875\n",
      "[train] Epoch: 5/80 Batch: 500/952 Loss: 0.1278735101222992 Accuracy: 93.75\n",
      "[train] Epoch: 5/80 Batch: 600/952 Loss: 0.21320372819900513 Accuracy: 90.625\n",
      "[train] Epoch: 5/80 Batch: 700/952 Loss: 0.17341375350952148 Accuracy: 90.625\n",
      "[train] Epoch: 5/80 Batch: 800/952 Loss: 0.004495907109230757 Accuracy: 100.0\n",
      "[train] Epoch: 5/80 Batch: 900/952 Loss: 0.012044363655149937 Accuracy: 100.0\n",
      "[train] Epoch: 5/80 Loss: 0.06875346640448948 Accuracy: 97.83571077225774 Execution time: 988.5921392440796\n",
      "[val] Epoch: 5/80 Batch: 100/238 Loss: 0.0050530810840427876 Accuracy: 100.0\n",
      "[val] Epoch: 5/80 Batch: 200/238 Loss: 0.003323527052998543 Accuracy: 100.0\n",
      "[val] Epoch: 5/80 Loss: 0.11904955533945574 Accuracy: 97.5731339367703 Execution time: 225.47037315368652\n",
      "[train] Epoch: 6/80 Batch: 100/952 Loss: 0.0006929230876266956 Accuracy: 100.0\n",
      "[train] Epoch: 6/80 Batch: 200/952 Loss: 0.19244502484798431 Accuracy: 93.75\n",
      "[train] Epoch: 6/80 Batch: 300/952 Loss: 0.00029048690339550376 Accuracy: 100.0\n",
      "[train] Epoch: 6/80 Batch: 400/952 Loss: 0.022894956171512604 Accuracy: 100.0\n",
      "[train] Epoch: 6/80 Batch: 500/952 Loss: 0.061145707964897156 Accuracy: 96.875\n",
      "[train] Epoch: 6/80 Batch: 600/952 Loss: 0.0008482645498588681 Accuracy: 100.0\n",
      "[train] Epoch: 6/80 Batch: 700/952 Loss: 0.00044537478243000805 Accuracy: 100.0\n",
      "[train] Epoch: 6/80 Batch: 800/952 Loss: 0.00032643601298332214 Accuracy: 100.0\n",
      "[train] Epoch: 6/80 Batch: 900/952 Loss: 0.0003222834493499249 Accuracy: 100.0\n",
      "[train] Epoch: 6/80 Loss: 0.06070820860256864 Accuracy: 97.92097065092638 Execution time: 544.1919689178467\n",
      "[val] Epoch: 6/80 Batch: 100/238 Loss: 0.0935649424791336 Accuracy: 96.875\n",
      "[val] Epoch: 6/80 Batch: 200/238 Loss: 0.10855735838413239 Accuracy: 96.875\n",
      "[val] Epoch: 6/80 Loss: 0.11971943495305462 Accuracy: 97.20582447855175 Execution time: 134.64068055152893\n",
      "[train] Epoch: 7/80 Batch: 100/952 Loss: 0.003929394297301769 Accuracy: 100.0\n",
      "[train] Epoch: 7/80 Batch: 200/952 Loss: 0.12428348511457443 Accuracy: 96.875\n",
      "[train] Epoch: 7/80 Batch: 300/952 Loss: 0.21497678756713867 Accuracy: 90.625\n",
      "[train] Epoch: 7/80 Batch: 400/952 Loss: 0.10985992103815079 Accuracy: 96.875\n",
      "[train] Epoch: 7/80 Batch: 500/952 Loss: 0.17368200421333313 Accuracy: 93.75\n",
      "[train] Epoch: 7/80 Batch: 600/952 Loss: 0.14371559023857117 Accuracy: 93.75\n",
      "[train] Epoch: 7/80 Batch: 700/952 Loss: 0.1331312507390976 Accuracy: 96.875\n",
      "[train] Epoch: 7/80 Batch: 800/952 Loss: 0.2506330609321594 Accuracy: 90.625\n",
      "[train] Epoch: 7/80 Batch: 900/952 Loss: 0.12842957675457 Accuracy: 96.875\n",
      "[train] Epoch: 7/80 Loss: 0.058156156821466846 Accuracy: 97.92424987702903 Execution time: 597.0628426074982\n",
      "[val] Epoch: 7/80 Batch: 100/238 Loss: 0.0002063113934127614 Accuracy: 100.0\n",
      "[val] Epoch: 7/80 Batch: 200/238 Loss: 0.0002948015171568841 Accuracy: 100.0\n",
      "[val] Epoch: 7/80 Loss: 0.12215918165348273 Accuracy: 97.61248852157944 Execution time: 162.8623719215393\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "with open('datasets/processed/hico/anno_list.json') as f:\n",
    "    anno_list = json.load(f)\n",
    "    \n",
    "img_cache = {} # format {key: [human, object, pairwise]}\n",
    "img_cache_counter = 0\n",
    "    \n",
    "print('Training has started!')\n",
    "    \n",
    "for epoch in range(epochs):\n",
    "    epoch_loss = 0\n",
    "    epoch_accuracy = 0\n",
    "    for phase in ['train', 'val']:\n",
    "        start_time = time.time()\n",
    "        running_loss = 0.0\n",
    "        running_correct = 0\n",
    "        idx = 0\n",
    "        \n",
    "        for data in dataloader[phase]:\n",
    "            train_data = data\n",
    "            img_name = train_data['img_name']\n",
    "            \n",
    "            labels = np.zeros((batch_size, 600))\n",
    "            batch_correct = 0\n",
    "            for i in range(batch_size):\n",
    "                # Get image data\n",
    "                parsed_img_name = img_name[i].split(\".\")[0]\n",
    "                img = [x for x in anno_list if x['global_id'] == parsed_img_name][0]\n",
    "                img = img['hois'][0]\n",
    "                img_id = int(img['id']) - 1\n",
    "                labels[i][img_id] = 1\n",
    "                human_bboxes = img['human_bboxes']\n",
    "                object_bboxes = img['object_bboxes']\n",
    "\n",
    "                # Apply masks to images [with caching]\n",
    "                src_img_path = TRAIN_IMG_PATH + 'HICO_train2015_' + img['id'].rjust(8, '0') + '.jpg'\n",
    "                if src_img_path in img_cache: # Use cache if available\n",
    "                    human_bbox_img, obj_bbox_img, pairwise_bbox_img = img_cache[src_img_path]\n",
    "                else:\n",
    "                    src = cv2.imread(src_img_path)\n",
    "                    human_mask = np.zeros_like(src)\n",
    "                    for bbox in human_bboxes:\n",
    "                        cv2.rectangle(human_mask, (bbox[0], bbox[1]), (bbox[2], bbox[3]), (255, 255, 255), thickness=-1)\n",
    "                    human_bbox_img = cv2.bitwise_and(src, human_mask, mask=None)\n",
    "\n",
    "                    obj_mask = np.zeros_like(src)\n",
    "                    pairwise_mask = human_mask\n",
    "                    for bbox in object_bboxes:\n",
    "                        cv2.rectangle(obj_mask, (bbox[0], bbox[1]), (bbox[2], bbox[3]), (255, 255, 255), thickness=-1)\n",
    "                        cv2.rectangle(pairwise_mask, (bbox[0], bbox[1]), (bbox[2], bbox[3]), (255, 255, 255), thickness=-1)\n",
    "                    obj_bbox_img = cv2.bitwise_and(src, obj_mask, mask=None)\n",
    "                    pairwise_bbox_img = cv2.bitwise_and(src, pairwise_mask, mask=None)\n",
    "                    \n",
    "                    # Add to cache if within limits\n",
    "                    if not max_img_cache_size or img_cache_counter < max_img_cache_size:\n",
    "                        img_cache[src_img_path] = [human_bbox_img, obj_bbox_img, pairwise_bbox_img]\n",
    "                        img_cache_counter += 1\n",
    "\n",
    "                '''\n",
    "                # Visualization of masks\n",
    "                f, axarr = plt.subplots(1,3)\n",
    "\n",
    "                human_bbox_rgb = cv2.cvtColor(human_bbox_img, cv2.COLOR_BGR2RGB)\n",
    "                axarr[0].imshow(human_bbox_rgb)\n",
    "\n",
    "                object_mask_rgb = cv2.cvtColor(obj_bbox_img, cv2.COLOR_BGR2RGB)\n",
    "                axarr[1].imshow(object_mask_rgb)\n",
    "\n",
    "                pairwise_rgb = cv2.cvtColor(pairwise_bbox_img, cv2.COLOR_BGR2RGB)\n",
    "                axarr[2].imshow(pairwise_rgb)\n",
    "\n",
    "                plt.show()\n",
    "                f.clf()\n",
    "                '''\n",
    "\n",
    "                human_bbox_img = cv2.resize(human_bbox_img, (64, 64), interpolation=cv2.INTER_AREA)\n",
    "                obj_bbox_img = cv2.resize(obj_bbox_img, (64, 64), interpolation=cv2.INTER_AREA)\n",
    "                pairwise_bbox_img = cv2.resize(pairwise_bbox_img, (64, 64), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "                human_bbox_img = torch.from_numpy(human_bbox_img).to(device)\n",
    "                obj_bbox_img = torch.from_numpy(obj_bbox_img).to(device)\n",
    "                pairwise_bbox_img = torch.from_numpy(pairwise_bbox_img).to(device)\n",
    "\n",
    "                if i == 0:\n",
    "                    res_human_input = human_bbox_img.unsqueeze(0)\n",
    "                    res_obj_input = obj_bbox_img.unsqueeze(0)\n",
    "                    res_pairwise_input = pairwise_bbox_img.unsqueeze(0)\n",
    "                else:\n",
    "                    res_human_input = torch.cat((res_human_input, human_bbox_img.unsqueeze(0)), dim=0)\n",
    "                    res_obj_input = torch.cat((res_obj_input, obj_bbox_img.unsqueeze(0)), dim=0)\n",
    "                    res_pairwise_input = torch.cat((res_pairwise_input, pairwise_bbox_img.unsqueeze(0)), dim=0)\n",
    "\n",
    "            res_human_input = res_human_input.permute([0,3,1,2]).float().to(device)\n",
    "            res_obj_input = res_obj_input.permute([0,3,1,2]).float().to(device)\n",
    "            res_pairwise_input = res_pairwise_input.permute([0,3,1,2]).float().to(device)\n",
    "            labels = torch.from_numpy(labels).long().to(device)\n",
    "            \n",
    "            if phase == 'train':\n",
    "                # Initial train loop\n",
    "                model.train()\n",
    "                model.zero_grad()\n",
    "                \n",
    "                # Forward pass: human, objects, pairwise streams\n",
    "                outputs = model.forward(res_human_input, res_obj_input, res_pairwise_input)\n",
    "                loss = criterion(outputs, torch.max(labels, 1)[1])\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                preds = torch.argmax(outputs, dim=1)\n",
    "                ground_labels = torch.max(labels, 1)[1]\n",
    "                for accuracy_iterator in range(len(ground_labels)):\n",
    "                    if preds[accuracy_iterator] == ground_labels[accuracy_iterator]:\n",
    "                        batch_correct += 1\n",
    "                \n",
    "            else:\n",
    "                # Evaluation after train loop\n",
    "                model.eval()\n",
    "                with torch.no_grad(): # Disable gradients for validation\n",
    "                    outputs = model.forward(res_human_input, res_obj_input, res_pairwise_input)\n",
    "                    loss = criterion(outputs, torch.max(labels, 1)[1])\n",
    "                    \n",
    "                    preds = torch.argmax(outputs, dim=1)\n",
    "                    ground_labels = torch.max(labels, 1)[1]\n",
    "                    for accuracy_iterator in range(len(ground_labels)):\n",
    "                        if preds[accuracy_iterator] == ground_labels[accuracy_iterator]:\n",
    "                            batch_correct += 1\n",
    "                    \n",
    "            # Accumulate loss of each batch (average * batch size)\n",
    "            running_loss += loss.item() * batch_size\n",
    "            running_correct += batch_correct\n",
    "            \n",
    "            # Print out status per print_batch_every\n",
    "            idx += 1\n",
    "            if (idx % print_batch_every) == 0:\n",
    "                print(\"[{}] Epoch: {}/{} Batch: {}/{} Loss: {} Accuracy: {}\".format(\\\n",
    "                        phase, epoch+1, epochs, idx, len(dataloader[phase]), \\\n",
    "                        loss.item(), 100 * batch_correct / batch_size))\n",
    "            \n",
    "        # Epoch loss and accuracy\n",
    "        epoch_loss = running_loss / len(dataset[phase])\n",
    "        epoch_accuracy = 100 * running_correct / len(dataset[phase])\n",
    "        \n",
    "        # Log trainval data for visualization\n",
    "        if phase == 'train':\n",
    "            train_loss = epoch_loss \n",
    "            train_accuracy = epoch_accuracy\n",
    "        else:\n",
    "            writer.add_scalars('trainval_loss_epoch', {'train': train_loss, 'val': epoch_loss}, epoch)\n",
    "            writer.add_scalars('trainval_accuracy_epoch', {'train': train_accuracy, 'val': epoch_accuracy}, epoch)\n",
    "            \n",
    "        # Output data per print_epoch_every\n",
    "        if (epoch % print_epoch_every) == 0:\n",
    "            end_time = time.time()\n",
    "            print(\"[{}] Epoch: {}/{} Loss: {} Accuracy: {} Execution time: {}\".format(\\\n",
    "                    phase, epoch+1, epochs, epoch_loss, epoch_accuracy, (end_time-start_time)))\n",
    "    \n",
    "    # Save the model per save_every\n",
    "    if epoch_loss<0.0405 or epoch % save_every == (save_every - 1) and epoch >= (10-1):\n",
    "        checkpoint = { \n",
    "                        'lr': initial_lr,\n",
    "                       'b_s': batch_size,\n",
    "                 'feat_type': feat_type,\n",
    "                'state_dict': model.state_dict()\n",
    "        }\n",
    "        save_name = \"checkpoint_\" + str(epoch+1) + '_epoch.pth'\n",
    "        torch.save(checkpoint, os.path.join(save_dir, exp_ver, 'epoch_train', save_name))\n",
    "        \n",
    "print('Finishing training!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close visualization\n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "interact",
   "language": "python",
   "name": "interact"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
