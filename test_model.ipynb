{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn, optim\n",
    "import cv2\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "from model.cnn_model import HOCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"HICO/v5/\"\n",
    "epoch_num = \"10\"\n",
    "checkpoint_path = \"checkpoint_\" + epoch_num + \"_epoch.pth\"\n",
    "\n",
    "PATH = \"checkpoints/\" + model + \"epoch_train/\" + checkpoint_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(PATH)\n",
    "model = HOCNN()\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "model.eval()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_PATH = \"datasets/hico/images/test2015/HICO_test2015_00000001.jpg\"\n",
    "human_bboxes = [[319, 305, 358, 348],\n",
    "                [269, 302, 310, 349]] # 2d matrix of bbox coords -- bottom left, top right\n",
    "object_bboxes = [[147, 344, 375, 413]]\n",
    "\n",
    "# apply masks\n",
    "src = cv2.imread(IMG_PATH)\n",
    "human_mask = np.zeros_like(src)\n",
    "for bbox in human_bboxes:\n",
    "    cv2.rectangle(human_mask, (bbox[0], bbox[1]), (bbox[2], bbox[3]), (255, 255, 255), thickness=-1)\n",
    "human_bbox_img = cv2.bitwise_and(src, human_mask, mask=None)\n",
    "\n",
    "obj_mask = np.zeros_like(src)\n",
    "pairwise_mask = human_mask\n",
    "for bbox in object_bboxes:\n",
    "    cv2.rectangle(obj_mask, (bbox[0], bbox[1]), (bbox[2], bbox[3]), (255, 255, 255), thickness=-1)\n",
    "    cv2.rectangle(pairwise_mask, (bbox[0], bbox[1]), (bbox[2], bbox[3]), (255, 255, 255), thickness=-1)\n",
    "obj_bbox_img = cv2.bitwise_and(src, obj_mask, mask=None)\n",
    "pairwise_bbox_img = cv2.bitwise_and(src, pairwise_mask, mask=None)\n",
    "\n",
    "# resize images\n",
    "human_bbox_img = cv2.resize(human_bbox_img, (64, 64), interpolation=cv2.INTER_AREA)\n",
    "obj_bbox_img = cv2.resize(obj_bbox_img, (64, 64), interpolation=cv2.INTER_AREA)\n",
    "pairwise_bbox_img = cv2.resize(pairwise_bbox_img, (64, 64), interpolation=cv2.INTER_AREA)\n",
    "#pose_img = cv2.resize(pose_img, (64, 64), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "human_bbox_img = torch.from_numpy(human_bbox_img).to(device)\n",
    "obj_bbox_img = torch.from_numpy(obj_bbox_img).to(device)\n",
    "pairwise_bbox_img = torch.from_numpy(pairwise_bbox_img).to(device)\n",
    "#pose_img = torch.from_numpy(pose_img).to(device)\n",
    "\n",
    "\n",
    "res_human_input = human_bbox_img.unsqueeze(0)\n",
    "res_obj_input = obj_bbox_img.unsqueeze(0)\n",
    "res_pairwise_input = pairwise_bbox_img.unsqueeze(0)\n",
    "#res_pose_input = pose_img.unsqueeze(0)\n",
    "\n",
    "res_human_input = res_human_input.permute([0,3,1,2]).float().to(device)\n",
    "res_obj_input = res_obj_input.permute([0,3,1,2]).float().to(device)\n",
    "res_pairwise_input = res_pairwise_input.permute([0,3,1,2]).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([245])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad(): # Disable gradients for validation\n",
    "    outputs = model.forward(res_human_input, res_obj_input, res_pairwise_input)\n",
    "\n",
    "    preds = torch.argmax(outputs, dim=1)\n",
    "   # ground_labels = torch.max(labels, 1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '245', 'object': 'bench', 'verb': 'lie_on'}\n"
     ]
    }
   ],
   "source": [
    "with open('datasets/processed/hico/hoi_list.json') as f:\n",
    "    hoi_list = json.load(f)\n",
    "prediction = hoi_list[preds.item()-1]\n",
    "print(prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "interact-venv",
   "language": "python",
   "name": "interact-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
